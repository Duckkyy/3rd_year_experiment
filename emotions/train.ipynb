{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! git clone https://github.com/Duckkyy/3rd_year_experiment.git","metadata":{"execution":{"iopub.status.busy":"2023-01-05T09:43:35.480450Z","iopub.execute_input":"2023-01-05T09:43:35.481445Z","iopub.status.idle":"2023-01-05T09:44:10.418073Z","shell.execute_reply.started":"2023-01-05T09:43:35.481325Z","shell.execute_reply":"2023-01-05T09:44:10.416931Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into '3rd_year_experiment'...\nremote: Enumerating objects: 37126, done.\u001b[K\nremote: Counting objects: 100% (2230/2230), done.\u001b[K\nremote: Compressing objects: 100% (2100/2100), done.\u001b[K\nremote: Total 37126 (delta 120), reused 2229 (delta 119), pack-reused 34896\u001b[K\nReceiving objects: 100% (37126/37126), 913.52 MiB | 38.30 MiB/s, done.\nResolving deltas: 100% (14164/14164), done.\nUpdating files: 100% (38760/38760), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls 3rd_year_experiment/emotions/data/train\nimport shutil\nimport os\ntrain_dir = '3rd_year_experiment/emotions/data/train'\nval_dir = '3rd_year_experiment/emotions/data/val'\nfor i in range(1, 8):\n    val_dir_idx = os.path.join(val_dir, str(i))\n    train_dir_idx = os.path.join(train_dir, str(i))\n    for fol in os.listdir(val_dir_idx):\n        val_dir_path = os.path.join(val_dir_idx, fol)\n        train_dir_path = os.path.join(train_dir_idx, fol)\n        for image in os.listdir(val_dir_path):\n            val_image_path = os.path.join(val_dir_path, image)\n            # print(val_image_path)\n            shutil.copy(val_image_path, train_dir_path)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T09:46:38.277741Z","iopub.execute_input":"2023-01-05T09:46:38.278147Z","iopub.status.idle":"2023-01-05T09:46:39.352364Z","shell.execute_reply.started":"2023-01-05T09:46:38.278111Z","shell.execute_reply":"2023-01-05T09:46:39.351249Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"1  2  3  4  5  6  7\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sb\nimport cv2\nfrom torch.utils.data import Dataset, DataLoader\nimport io \nimport os \nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2023-01-05T09:46:42.370228Z","iopub.execute_input":"2023-01-05T09:46:42.370617Z","iopub.status.idle":"2023-01-05T09:46:45.014308Z","shell.execute_reply.started":"2023-01-05T09:46:42.370581Z","shell.execute_reply":"2023-01-05T09:46:45.013088Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from __future__ import print_function\nfrom __future__ import division\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport time \nimport copy","metadata":{"execution":{"iopub.status.busy":"2023-01-05T09:46:45.016662Z","iopub.execute_input":"2023-01-05T09:46:45.017444Z","iopub.status.idle":"2023-01-05T09:46:45.298354Z","shell.execute_reply.started":"2023-01-05T09:46:45.017369Z","shell.execute_reply":"2023-01-05T09:46:45.297385Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#Dataloader\ndata_path = '3rd_year_experiment/emotions/data/'\n#Path for training and testing directory\ntrain_dir = os.path.join(data_path, 'train')\ntest_dir = os.path.join(data_path, 'test')","metadata":{"execution":{"iopub.status.busy":"2023-01-05T09:46:47.590307Z","iopub.execute_input":"2023-01-05T09:46:47.591141Z","iopub.status.idle":"2023-01-05T09:46:47.596711Z","shell.execute_reply.started":"2023-01-05T09:46:47.591105Z","shell.execute_reply":"2023-01-05T09:46:47.595526Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_data_path = '3rd_year_experiment/emotions/Labels/ground_truth_train.csv'\ntrain_data = pd.read_csv(train_data_path)\ntrain_data.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T09:46:50.434175Z","iopub.execute_input":"2023-01-05T09:46:50.434652Z","iopub.status.idle":"2023-01-05T09:46:50.465959Z","shell.execute_reply.started":"2023-01-05T09:46:50.434614Z","shell.execute_reply":"2023-01-05T09:46:50.465100Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"            image  label\n0   disgust/1.jpg      2\n1  surprise/1.jpg      4\n2      fear/1.jpg      3\n3       joy/1.jpg      4\n4   sadness/1.jpg      5","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>disgust/1.jpg</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>surprise/1.jpg</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>fear/1.jpg</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>joy/1.jpg</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>sadness/1.jpg</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"labelArr = train_data['label'].unique()\nlabel2id = {}\nid2label = {}\nindex = 0\nfor class_name in labelArr:\n    label2id[class_name] = str(index)\n    id2label[str(index)] = class_name\n    index += 1\nprint(label2id)\nprint(id2label)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T09:46:53.010314Z","iopub.execute_input":"2023-01-05T09:46:53.010791Z","iopub.status.idle":"2023-01-05T09:46:53.031600Z","shell.execute_reply.started":"2023-01-05T09:46:53.010749Z","shell.execute_reply":"2023-01-05T09:46:53.030639Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"{2: '0', 4: '1', 3: '2', 5: '3', 7: '4', 6: '5', 1: '6'}\n{'0': 2, '1': 4, '2': 3, '3': 5, '4': 7, '5': 6, '6': 1}\n","output_type":"stream"}]},{"cell_type":"code","source":"model_name = 'resnet'\nnum_classes = 7\nbatch_size = 64\nnum_epochs = 50\nfeature_extract = False","metadata":{"execution":{"iopub.status.busy":"2023-01-05T09:46:55.158523Z","iopub.execute_input":"2023-01-05T09:46:55.159031Z","iopub.status.idle":"2023-01-05T09:46:55.165424Z","shell.execute_reply.started":"2023-01-05T09:46:55.158981Z","shell.execute_reply":"2023-01-05T09:46:55.164207Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain, valid = train_test_split(train_data, test_size=0.05)\nprint(len(train))\nprint(len(valid))","metadata":{"execution":{"iopub.status.busy":"2023-01-05T09:46:58.328929Z","iopub.execute_input":"2023-01-05T09:46:58.329405Z","iopub.status.idle":"2023-01-05T09:46:58.465208Z","shell.execute_reply.started":"2023-01-05T09:46:58.329352Z","shell.execute_reply":"2023-01-05T09:46:58.463686Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"1507\n80\n","output_type":"stream"}]},{"cell_type":"code","source":"train['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-01-05T09:47:00.657750Z","iopub.execute_input":"2023-01-05T09:47:00.658111Z","iopub.status.idle":"2023-01-05T09:47:00.669139Z","shell.execute_reply.started":"2023-01-05T09:47:00.658080Z","shell.execute_reply":"2023-01-05T09:47:00.668004Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"4    486\n7    252\n3    251\n5    228\n2    188\n6     79\n1     23\nName: label, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"class EmotionDataset(Dataset):\n    def __init__(self, dataframe, root_dir, is_train, transform=None):\n        self.dataframe = dataframe\n        self.root_dir = root_dir\n        self.transform = transform\n        self.is_train = is_train\n        \n    def __len__(self):\n        return len(self.dataframe)\n    \n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n            \n        img_name = os.path.join(self.root_dir, str(self.dataframe.iloc[idx, 1]), self.dataframe.iloc[idx, 0])\n        image1 = cv2.imread(img_name)\n        image = Image.fromarray(image1)\n        if self.is_train:\n            labelKey = self.dataframe.iloc[idx, 1]\n            label = torch.tensor(int(label2id[labelKey]))\n            \n        else:\n            label = torch.tensor(1)\n            \n        if self.transform:\n            image = self.transform(image)\n            \n        return image, label","metadata":{"execution":{"iopub.status.busy":"2023-01-05T09:47:03.086201Z","iopub.execute_input":"2023-01-05T09:47:03.086640Z","iopub.status.idle":"2023-01-05T09:47:03.098382Z","shell.execute_reply.started":"2023-01-05T09:47:03.086603Z","shell.execute_reply":"2023-01-05T09:47:03.097274Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"input_size = 224\ntransform_train = transforms.Compose([\n    transforms.RandomVerticalFlip(),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(30),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\ntransform_valid = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])","metadata":{"execution":{"iopub.status.busy":"2023-01-05T09:47:05.777916Z","iopub.execute_input":"2023-01-05T09:47:05.778306Z","iopub.status.idle":"2023-01-05T09:47:05.785675Z","shell.execute_reply.started":"2023-01-05T09:47:05.778273Z","shell.execute_reply":"2023-01-05T09:47:05.784555Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_dataset = EmotionDataset(train, root_dir=train_dir, is_train=True, transform=transform_train)\nvalid_dataset = EmotionDataset(valid, root_dir=train_dir, is_train=True, transform=transform_valid)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=2, shuffle=True)\nval_loader =torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, num_workers=2)\ndataloaders_dict ={}\ndataloaders_dict['train']= train_loader\ndataloaders_dict['val'] = val_loader","metadata":{"execution":{"iopub.status.busy":"2023-01-05T09:47:20.115082Z","iopub.execute_input":"2023-01-05T09:47:20.115475Z","iopub.status.idle":"2023-01-05T09:47:20.122532Z","shell.execute_reply.started":"2023-01-05T09:47:20.115439Z","shell.execute_reply":"2023-01-05T09:47:20.121274Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# for i, (images,labels) in enumerate(train_loader):\n#     print(images)\ntrain_features, train_labels = next(iter(train_loader))\nprint(f\"Feature batch shape: {train_features.size()}\")\nprint(f\"Labels batch shape: {train_labels.size()}\")\nimg = train_features[1].squeeze()\nimg = (img.T).detach().numpy()\nlabel = train_labels[0]\nplt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\nplt.show()\nprint(f\"Label: {label}\")","metadata":{"execution":{"iopub.status.busy":"2023-01-05T09:47:22.640345Z","iopub.execute_input":"2023-01-05T09:47:22.641301Z","iopub.status.idle":"2023-01-05T09:47:24.623397Z","shell.execute_reply.started":"2023-01-05T09:47:22.641264Z","shell.execute_reply":"2023-01-05T09:47:24.622271Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Feature batch shape: torch.Size([64, 3, 224, 224])\nLabels batch shape: torch.Size([64])\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:2314.)\n  import sys\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"name":"stdout","text":"Label: 2\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n    since = time.time()\n\n    val_acc_history = []\n    \n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                #print(inputs)\n                #print(labels)\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    # Get model outputs and calculate loss\n                    # Special case for inception because in training it has an auxiliary output. In train\n                    #   mode we calculate the loss by summing the final output and the auxiliary output\n                    #   but in testing we only consider the final output.\n                    if is_inception and phase == 'train':\n                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n                        outputs, aux_outputs = model(inputs)\n                        loss1 = criterion(outputs, labels)\n                        loss2 = criterion(aux_outputs, labels)\n                        loss = loss1 + 0.4*loss2\n                    else:\n                        outputs = model(inputs)\n                        loss = criterion(outputs, labels)\n\n                    _, preds = torch.max(outputs, 1)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n            if phase == 'val':\n                val_acc_history.append(epoch_acc)\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model, val_acc_history","metadata":{"execution":{"iopub.status.busy":"2023-01-05T09:47:28.144658Z","iopub.execute_input":"2023-01-05T09:47:28.145023Z","iopub.status.idle":"2023-01-05T09:47:28.308770Z","shell.execute_reply.started":"2023-01-05T09:47:28.144992Z","shell.execute_reply":"2023-01-05T09:47:28.307624Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def set_parameter_requires_grad(model, feature_extracting):\n    if feature_extracting:\n        for param in model.parameters():\n            param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2023-01-05T09:47:31.733340Z","iopub.execute_input":"2023-01-05T09:47:31.733929Z","iopub.status.idle":"2023-01-05T09:47:31.746224Z","shell.execute_reply.started":"2023-01-05T09:47:31.733817Z","shell.execute_reply":"2023-01-05T09:47:31.744876Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n    # Initialize these variables which will be set in this if statement. Each of these\n    #   variables is model specific.\n    model_ft = None\n    input_size = 0\n\n    if model_name == \"resnet\":\n        \"\"\" Resnet18\n        \"\"\"\n        #models.resnet.model_urls[\"resnet50\"] = \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\"\n        model_ft = models.resnet18(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.fc.in_features\n        \n        model_ft.fc =  nn.Sequential(nn.Dropout(0.1),\n                                     nn.Linear(num_ftrs, num_classes)\n                                    )\n        input_size = 224\n\n    elif model_name == \"alexnet\":\n        \"\"\" Alexnet\n        \"\"\"\n        model_ft = models.alexnet(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.classifier[6].in_features\n        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n        input_size = 224\n\n    elif model_name == \"vgg\":\n        \"\"\" VGG11_bn\n        \"\"\"\n        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.classifier[6].in_features\n        model_ft.classifier[6] =  nn.Sequential(nn.Dropout(0.1),\n                                     nn.Linear(num_ftrs, num_classes)\n                                    )\n        input_size = 224\n\n    elif model_name == \"squeezenet\":\n        \"\"\" Squeezenet\n        \"\"\"\n        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n        model_ft.num_classes = num_classes\n        \n        input_size = 224\n\n    elif model_name == \"densenet\":\n        \"\"\" Densenet\n        \"\"\"\n        model_ft = models.densenet121(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.classifier.in_features\n        model_ft.classifier = nn.Linear(num_ftrs, num_classes) \n        input_size = 224\n\n    elif model_name == \"inception\":\n        \"\"\" Inception v3 \n        Be careful, expects (299,299) sized images and has auxiliary output\n        \"\"\"\n        model_ft = models.inception_v3(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        # Handle the auxilary net\n        num_ftrs = model_ft.AuxLogits.fc.in_features\n        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n        # Handle the primary net\n        num_ftrs = model_ft.fc.in_features\n        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n        input_size = 299\n    \n\n    else:\n        print(\"Invalid model name, exiting...\")\n        exit()\n    \n    return model_ft, input_size\n\nmodel_name = 'densenet'\n# Initialize the model for this run\nmodel_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n\n# Print the model we just instantiated\nprint(model_ft)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T09:47:35.021263Z","iopub.execute_input":"2023-01-05T09:47:35.021807Z","iopub.status.idle":"2023-01-05T09:47:37.332528Z","shell.execute_reply.started":"2023-01-05T09:47:35.021769Z","shell.execute_reply":"2023-01-05T09:47:37.331418Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/30.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbe7eb4eb7a14063b489fc6da125871a"}},"metadata":{}},{"name":"stdout","text":"DenseNet(\n  (features): Sequential(\n    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu0): ReLU(inplace=True)\n    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (denseblock1): _DenseBlock(\n      (denselayer1): _DenseLayer(\n        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer2): _DenseLayer(\n        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer3): _DenseLayer(\n        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer4): _DenseLayer(\n        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer5): _DenseLayer(\n        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer6): _DenseLayer(\n        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n    )\n    (transition1): _Transition(\n      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    )\n    (denseblock2): _DenseBlock(\n      (denselayer1): _DenseLayer(\n        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer2): _DenseLayer(\n        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer3): _DenseLayer(\n        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer4): _DenseLayer(\n        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer5): _DenseLayer(\n        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer6): _DenseLayer(\n        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer7): _DenseLayer(\n        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer8): _DenseLayer(\n        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer9): _DenseLayer(\n        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer10): _DenseLayer(\n        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer11): _DenseLayer(\n        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer12): _DenseLayer(\n        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n    )\n    (transition2): _Transition(\n      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    )\n    (denseblock3): _DenseBlock(\n      (denselayer1): _DenseLayer(\n        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer2): _DenseLayer(\n        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer3): _DenseLayer(\n        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer4): _DenseLayer(\n        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer5): _DenseLayer(\n        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer6): _DenseLayer(\n        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer7): _DenseLayer(\n        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer8): _DenseLayer(\n        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer9): _DenseLayer(\n        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer10): _DenseLayer(\n        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer11): _DenseLayer(\n        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer12): _DenseLayer(\n        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer13): _DenseLayer(\n        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer14): _DenseLayer(\n        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer15): _DenseLayer(\n        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer16): _DenseLayer(\n        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer17): _DenseLayer(\n        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer18): _DenseLayer(\n        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer19): _DenseLayer(\n        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer20): _DenseLayer(\n        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer21): _DenseLayer(\n        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer22): _DenseLayer(\n        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer23): _DenseLayer(\n        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer24): _DenseLayer(\n        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n    )\n    (transition3): _Transition(\n      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    )\n    (denseblock4): _DenseBlock(\n      (denselayer1): _DenseLayer(\n        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer2): _DenseLayer(\n        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer3): _DenseLayer(\n        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer4): _DenseLayer(\n        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer5): _DenseLayer(\n        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer6): _DenseLayer(\n        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer7): _DenseLayer(\n        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer8): _DenseLayer(\n        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer9): _DenseLayer(\n        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer10): _DenseLayer(\n        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer11): _DenseLayer(\n        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer12): _DenseLayer(\n        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer13): _DenseLayer(\n        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer14): _DenseLayer(\n        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer15): _DenseLayer(\n        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer16): _DenseLayer(\n        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n    )\n    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (classifier): Linear(in_features=1024, out_features=7, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Send the model to GPU\ntorch.manual_seed(1)\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nif device == 'cuda':\n    torch.backends.cudnn.benchmark = True\nprint(f'using {device} device')\n#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel_ft = model_ft.to(device)\n\n# Gather the parameters to be optimized/updated in this run. If we are\n#  finetuning we will be updating all parameters. However, if we are \n#  doing feature extract method, we will only update the parameters\n#  that we have just initialized, i.e. the parameters with requires_grad\n#  is True.\nparams_to_update = model_ft.parameters()\nprint(\"Params to learn:\")\nif feature_extract:\n    params_to_update = []\n    for name,param in model_ft.named_parameters():\n        if param.requires_grad == True:\n            params_to_update.append(param)\n            print(\"\\t\",name)\nelse:\n    for name,param in model_ft.named_parameters():\n        if param.requires_grad == True:\n            print(\"\\t\",name)\n\n# Observe that all parameters are being optimized\noptimizer_ft = optim.SGD(params_to_update, lr=2e-3, momentum=0.9,weight_decay=1e-6, nesterov=True)\n#optimizer_ft = optim.Adam(params_to_update, lr=1e-3)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T09:47:44.815521Z","iopub.execute_input":"2023-01-05T09:47:44.815897Z","iopub.status.idle":"2023-01-05T09:47:48.315792Z","shell.execute_reply.started":"2023-01-05T09:47:44.815865Z","shell.execute_reply":"2023-01-05T09:47:48.314769Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"using cuda device\nParams to learn:\n\t features.conv0.weight\n\t features.norm0.weight\n\t features.norm0.bias\n\t features.denseblock1.denselayer1.norm1.weight\n\t features.denseblock1.denselayer1.norm1.bias\n\t features.denseblock1.denselayer1.conv1.weight\n\t features.denseblock1.denselayer1.norm2.weight\n\t features.denseblock1.denselayer1.norm2.bias\n\t features.denseblock1.denselayer1.conv2.weight\n\t features.denseblock1.denselayer2.norm1.weight\n\t features.denseblock1.denselayer2.norm1.bias\n\t features.denseblock1.denselayer2.conv1.weight\n\t features.denseblock1.denselayer2.norm2.weight\n\t features.denseblock1.denselayer2.norm2.bias\n\t features.denseblock1.denselayer2.conv2.weight\n\t features.denseblock1.denselayer3.norm1.weight\n\t features.denseblock1.denselayer3.norm1.bias\n\t features.denseblock1.denselayer3.conv1.weight\n\t features.denseblock1.denselayer3.norm2.weight\n\t features.denseblock1.denselayer3.norm2.bias\n\t features.denseblock1.denselayer3.conv2.weight\n\t features.denseblock1.denselayer4.norm1.weight\n\t features.denseblock1.denselayer4.norm1.bias\n\t features.denseblock1.denselayer4.conv1.weight\n\t features.denseblock1.denselayer4.norm2.weight\n\t features.denseblock1.denselayer4.norm2.bias\n\t features.denseblock1.denselayer4.conv2.weight\n\t features.denseblock1.denselayer5.norm1.weight\n\t features.denseblock1.denselayer5.norm1.bias\n\t features.denseblock1.denselayer5.conv1.weight\n\t features.denseblock1.denselayer5.norm2.weight\n\t features.denseblock1.denselayer5.norm2.bias\n\t features.denseblock1.denselayer5.conv2.weight\n\t features.denseblock1.denselayer6.norm1.weight\n\t features.denseblock1.denselayer6.norm1.bias\n\t features.denseblock1.denselayer6.conv1.weight\n\t features.denseblock1.denselayer6.norm2.weight\n\t features.denseblock1.denselayer6.norm2.bias\n\t features.denseblock1.denselayer6.conv2.weight\n\t features.transition1.norm.weight\n\t features.transition1.norm.bias\n\t features.transition1.conv.weight\n\t features.denseblock2.denselayer1.norm1.weight\n\t features.denseblock2.denselayer1.norm1.bias\n\t features.denseblock2.denselayer1.conv1.weight\n\t features.denseblock2.denselayer1.norm2.weight\n\t features.denseblock2.denselayer1.norm2.bias\n\t features.denseblock2.denselayer1.conv2.weight\n\t features.denseblock2.denselayer2.norm1.weight\n\t features.denseblock2.denselayer2.norm1.bias\n\t features.denseblock2.denselayer2.conv1.weight\n\t features.denseblock2.denselayer2.norm2.weight\n\t features.denseblock2.denselayer2.norm2.bias\n\t features.denseblock2.denselayer2.conv2.weight\n\t features.denseblock2.denselayer3.norm1.weight\n\t features.denseblock2.denselayer3.norm1.bias\n\t features.denseblock2.denselayer3.conv1.weight\n\t features.denseblock2.denselayer3.norm2.weight\n\t features.denseblock2.denselayer3.norm2.bias\n\t features.denseblock2.denselayer3.conv2.weight\n\t features.denseblock2.denselayer4.norm1.weight\n\t features.denseblock2.denselayer4.norm1.bias\n\t features.denseblock2.denselayer4.conv1.weight\n\t features.denseblock2.denselayer4.norm2.weight\n\t features.denseblock2.denselayer4.norm2.bias\n\t features.denseblock2.denselayer4.conv2.weight\n\t features.denseblock2.denselayer5.norm1.weight\n\t features.denseblock2.denselayer5.norm1.bias\n\t features.denseblock2.denselayer5.conv1.weight\n\t features.denseblock2.denselayer5.norm2.weight\n\t features.denseblock2.denselayer5.norm2.bias\n\t features.denseblock2.denselayer5.conv2.weight\n\t features.denseblock2.denselayer6.norm1.weight\n\t features.denseblock2.denselayer6.norm1.bias\n\t features.denseblock2.denselayer6.conv1.weight\n\t features.denseblock2.denselayer6.norm2.weight\n\t features.denseblock2.denselayer6.norm2.bias\n\t features.denseblock2.denselayer6.conv2.weight\n\t features.denseblock2.denselayer7.norm1.weight\n\t features.denseblock2.denselayer7.norm1.bias\n\t features.denseblock2.denselayer7.conv1.weight\n\t features.denseblock2.denselayer7.norm2.weight\n\t features.denseblock2.denselayer7.norm2.bias\n\t features.denseblock2.denselayer7.conv2.weight\n\t features.denseblock2.denselayer8.norm1.weight\n\t features.denseblock2.denselayer8.norm1.bias\n\t features.denseblock2.denselayer8.conv1.weight\n\t features.denseblock2.denselayer8.norm2.weight\n\t features.denseblock2.denselayer8.norm2.bias\n\t features.denseblock2.denselayer8.conv2.weight\n\t features.denseblock2.denselayer9.norm1.weight\n\t features.denseblock2.denselayer9.norm1.bias\n\t features.denseblock2.denselayer9.conv1.weight\n\t features.denseblock2.denselayer9.norm2.weight\n\t features.denseblock2.denselayer9.norm2.bias\n\t features.denseblock2.denselayer9.conv2.weight\n\t features.denseblock2.denselayer10.norm1.weight\n\t features.denseblock2.denselayer10.norm1.bias\n\t features.denseblock2.denselayer10.conv1.weight\n\t features.denseblock2.denselayer10.norm2.weight\n\t features.denseblock2.denselayer10.norm2.bias\n\t features.denseblock2.denselayer10.conv2.weight\n\t features.denseblock2.denselayer11.norm1.weight\n\t features.denseblock2.denselayer11.norm1.bias\n\t features.denseblock2.denselayer11.conv1.weight\n\t features.denseblock2.denselayer11.norm2.weight\n\t features.denseblock2.denselayer11.norm2.bias\n\t features.denseblock2.denselayer11.conv2.weight\n\t features.denseblock2.denselayer12.norm1.weight\n\t features.denseblock2.denselayer12.norm1.bias\n\t features.denseblock2.denselayer12.conv1.weight\n\t features.denseblock2.denselayer12.norm2.weight\n\t features.denseblock2.denselayer12.norm2.bias\n\t features.denseblock2.denselayer12.conv2.weight\n\t features.transition2.norm.weight\n\t features.transition2.norm.bias\n\t features.transition2.conv.weight\n\t features.denseblock3.denselayer1.norm1.weight\n\t features.denseblock3.denselayer1.norm1.bias\n\t features.denseblock3.denselayer1.conv1.weight\n\t features.denseblock3.denselayer1.norm2.weight\n\t features.denseblock3.denselayer1.norm2.bias\n\t features.denseblock3.denselayer1.conv2.weight\n\t features.denseblock3.denselayer2.norm1.weight\n\t features.denseblock3.denselayer2.norm1.bias\n\t features.denseblock3.denselayer2.conv1.weight\n\t features.denseblock3.denselayer2.norm2.weight\n\t features.denseblock3.denselayer2.norm2.bias\n\t features.denseblock3.denselayer2.conv2.weight\n\t features.denseblock3.denselayer3.norm1.weight\n\t features.denseblock3.denselayer3.norm1.bias\n\t features.denseblock3.denselayer3.conv1.weight\n\t features.denseblock3.denselayer3.norm2.weight\n\t features.denseblock3.denselayer3.norm2.bias\n\t features.denseblock3.denselayer3.conv2.weight\n\t features.denseblock3.denselayer4.norm1.weight\n\t features.denseblock3.denselayer4.norm1.bias\n\t features.denseblock3.denselayer4.conv1.weight\n\t features.denseblock3.denselayer4.norm2.weight\n\t features.denseblock3.denselayer4.norm2.bias\n\t features.denseblock3.denselayer4.conv2.weight\n\t features.denseblock3.denselayer5.norm1.weight\n\t features.denseblock3.denselayer5.norm1.bias\n\t features.denseblock3.denselayer5.conv1.weight\n\t features.denseblock3.denselayer5.norm2.weight\n\t features.denseblock3.denselayer5.norm2.bias\n\t features.denseblock3.denselayer5.conv2.weight\n\t features.denseblock3.denselayer6.norm1.weight\n\t features.denseblock3.denselayer6.norm1.bias\n\t features.denseblock3.denselayer6.conv1.weight\n\t features.denseblock3.denselayer6.norm2.weight\n\t features.denseblock3.denselayer6.norm2.bias\n\t features.denseblock3.denselayer6.conv2.weight\n\t features.denseblock3.denselayer7.norm1.weight\n\t features.denseblock3.denselayer7.norm1.bias\n\t features.denseblock3.denselayer7.conv1.weight\n\t features.denseblock3.denselayer7.norm2.weight\n\t features.denseblock3.denselayer7.norm2.bias\n\t features.denseblock3.denselayer7.conv2.weight\n\t features.denseblock3.denselayer8.norm1.weight\n\t features.denseblock3.denselayer8.norm1.bias\n\t features.denseblock3.denselayer8.conv1.weight\n\t features.denseblock3.denselayer8.norm2.weight\n\t features.denseblock3.denselayer8.norm2.bias\n\t features.denseblock3.denselayer8.conv2.weight\n\t features.denseblock3.denselayer9.norm1.weight\n\t features.denseblock3.denselayer9.norm1.bias\n\t features.denseblock3.denselayer9.conv1.weight\n\t features.denseblock3.denselayer9.norm2.weight\n\t features.denseblock3.denselayer9.norm2.bias\n\t features.denseblock3.denselayer9.conv2.weight\n\t features.denseblock3.denselayer10.norm1.weight\n\t features.denseblock3.denselayer10.norm1.bias\n\t features.denseblock3.denselayer10.conv1.weight\n\t features.denseblock3.denselayer10.norm2.weight\n\t features.denseblock3.denselayer10.norm2.bias\n\t features.denseblock3.denselayer10.conv2.weight\n\t features.denseblock3.denselayer11.norm1.weight\n\t features.denseblock3.denselayer11.norm1.bias\n\t features.denseblock3.denselayer11.conv1.weight\n\t features.denseblock3.denselayer11.norm2.weight\n\t features.denseblock3.denselayer11.norm2.bias\n\t features.denseblock3.denselayer11.conv2.weight\n\t features.denseblock3.denselayer12.norm1.weight\n\t features.denseblock3.denselayer12.norm1.bias\n\t features.denseblock3.denselayer12.conv1.weight\n\t features.denseblock3.denselayer12.norm2.weight\n\t features.denseblock3.denselayer12.norm2.bias\n\t features.denseblock3.denselayer12.conv2.weight\n\t features.denseblock3.denselayer13.norm1.weight\n\t features.denseblock3.denselayer13.norm1.bias\n\t features.denseblock3.denselayer13.conv1.weight\n\t features.denseblock3.denselayer13.norm2.weight\n\t features.denseblock3.denselayer13.norm2.bias\n\t features.denseblock3.denselayer13.conv2.weight\n\t features.denseblock3.denselayer14.norm1.weight\n\t features.denseblock3.denselayer14.norm1.bias\n\t features.denseblock3.denselayer14.conv1.weight\n\t features.denseblock3.denselayer14.norm2.weight\n\t features.denseblock3.denselayer14.norm2.bias\n\t features.denseblock3.denselayer14.conv2.weight\n\t features.denseblock3.denselayer15.norm1.weight\n\t features.denseblock3.denselayer15.norm1.bias\n\t features.denseblock3.denselayer15.conv1.weight\n\t features.denseblock3.denselayer15.norm2.weight\n\t features.denseblock3.denselayer15.norm2.bias\n\t features.denseblock3.denselayer15.conv2.weight\n\t features.denseblock3.denselayer16.norm1.weight\n\t features.denseblock3.denselayer16.norm1.bias\n\t features.denseblock3.denselayer16.conv1.weight\n\t features.denseblock3.denselayer16.norm2.weight\n\t features.denseblock3.denselayer16.norm2.bias\n\t features.denseblock3.denselayer16.conv2.weight\n\t features.denseblock3.denselayer17.norm1.weight\n\t features.denseblock3.denselayer17.norm1.bias\n\t features.denseblock3.denselayer17.conv1.weight\n\t features.denseblock3.denselayer17.norm2.weight\n\t features.denseblock3.denselayer17.norm2.bias\n\t features.denseblock3.denselayer17.conv2.weight\n\t features.denseblock3.denselayer18.norm1.weight\n\t features.denseblock3.denselayer18.norm1.bias\n\t features.denseblock3.denselayer18.conv1.weight\n\t features.denseblock3.denselayer18.norm2.weight\n\t features.denseblock3.denselayer18.norm2.bias\n\t features.denseblock3.denselayer18.conv2.weight\n\t features.denseblock3.denselayer19.norm1.weight\n\t features.denseblock3.denselayer19.norm1.bias\n\t features.denseblock3.denselayer19.conv1.weight\n\t features.denseblock3.denselayer19.norm2.weight\n\t features.denseblock3.denselayer19.norm2.bias\n\t features.denseblock3.denselayer19.conv2.weight\n\t features.denseblock3.denselayer20.norm1.weight\n\t features.denseblock3.denselayer20.norm1.bias\n\t features.denseblock3.denselayer20.conv1.weight\n\t features.denseblock3.denselayer20.norm2.weight\n\t features.denseblock3.denselayer20.norm2.bias\n\t features.denseblock3.denselayer20.conv2.weight\n\t features.denseblock3.denselayer21.norm1.weight\n\t features.denseblock3.denselayer21.norm1.bias\n\t features.denseblock3.denselayer21.conv1.weight\n\t features.denseblock3.denselayer21.norm2.weight\n\t features.denseblock3.denselayer21.norm2.bias\n\t features.denseblock3.denselayer21.conv2.weight\n\t features.denseblock3.denselayer22.norm1.weight\n\t features.denseblock3.denselayer22.norm1.bias\n\t features.denseblock3.denselayer22.conv1.weight\n\t features.denseblock3.denselayer22.norm2.weight\n\t features.denseblock3.denselayer22.norm2.bias\n\t features.denseblock3.denselayer22.conv2.weight\n\t features.denseblock3.denselayer23.norm1.weight\n\t features.denseblock3.denselayer23.norm1.bias\n\t features.denseblock3.denselayer23.conv1.weight\n\t features.denseblock3.denselayer23.norm2.weight\n\t features.denseblock3.denselayer23.norm2.bias\n\t features.denseblock3.denselayer23.conv2.weight\n\t features.denseblock3.denselayer24.norm1.weight\n\t features.denseblock3.denselayer24.norm1.bias\n\t features.denseblock3.denselayer24.conv1.weight\n\t features.denseblock3.denselayer24.norm2.weight\n\t features.denseblock3.denselayer24.norm2.bias\n\t features.denseblock3.denselayer24.conv2.weight\n\t features.transition3.norm.weight\n\t features.transition3.norm.bias\n\t features.transition3.conv.weight\n\t features.denseblock4.denselayer1.norm1.weight\n\t features.denseblock4.denselayer1.norm1.bias\n\t features.denseblock4.denselayer1.conv1.weight\n\t features.denseblock4.denselayer1.norm2.weight\n\t features.denseblock4.denselayer1.norm2.bias\n\t features.denseblock4.denselayer1.conv2.weight\n\t features.denseblock4.denselayer2.norm1.weight\n\t features.denseblock4.denselayer2.norm1.bias\n\t features.denseblock4.denselayer2.conv1.weight\n\t features.denseblock4.denselayer2.norm2.weight\n\t features.denseblock4.denselayer2.norm2.bias\n\t features.denseblock4.denselayer2.conv2.weight\n\t features.denseblock4.denselayer3.norm1.weight\n\t features.denseblock4.denselayer3.norm1.bias\n\t features.denseblock4.denselayer3.conv1.weight\n\t features.denseblock4.denselayer3.norm2.weight\n\t features.denseblock4.denselayer3.norm2.bias\n\t features.denseblock4.denselayer3.conv2.weight\n\t features.denseblock4.denselayer4.norm1.weight\n\t features.denseblock4.denselayer4.norm1.bias\n\t features.denseblock4.denselayer4.conv1.weight\n\t features.denseblock4.denselayer4.norm2.weight\n\t features.denseblock4.denselayer4.norm2.bias\n\t features.denseblock4.denselayer4.conv2.weight\n\t features.denseblock4.denselayer5.norm1.weight\n\t features.denseblock4.denselayer5.norm1.bias\n\t features.denseblock4.denselayer5.conv1.weight\n\t features.denseblock4.denselayer5.norm2.weight\n\t features.denseblock4.denselayer5.norm2.bias\n\t features.denseblock4.denselayer5.conv2.weight\n\t features.denseblock4.denselayer6.norm1.weight\n\t features.denseblock4.denselayer6.norm1.bias\n\t features.denseblock4.denselayer6.conv1.weight\n\t features.denseblock4.denselayer6.norm2.weight\n\t features.denseblock4.denselayer6.norm2.bias\n\t features.denseblock4.denselayer6.conv2.weight\n\t features.denseblock4.denselayer7.norm1.weight\n\t features.denseblock4.denselayer7.norm1.bias\n\t features.denseblock4.denselayer7.conv1.weight\n\t features.denseblock4.denselayer7.norm2.weight\n\t features.denseblock4.denselayer7.norm2.bias\n\t features.denseblock4.denselayer7.conv2.weight\n\t features.denseblock4.denselayer8.norm1.weight\n\t features.denseblock4.denselayer8.norm1.bias\n\t features.denseblock4.denselayer8.conv1.weight\n\t features.denseblock4.denselayer8.norm2.weight\n\t features.denseblock4.denselayer8.norm2.bias\n\t features.denseblock4.denselayer8.conv2.weight\n\t features.denseblock4.denselayer9.norm1.weight\n\t features.denseblock4.denselayer9.norm1.bias\n\t features.denseblock4.denselayer9.conv1.weight\n\t features.denseblock4.denselayer9.norm2.weight\n\t features.denseblock4.denselayer9.norm2.bias\n\t features.denseblock4.denselayer9.conv2.weight\n\t features.denseblock4.denselayer10.norm1.weight\n\t features.denseblock4.denselayer10.norm1.bias\n\t features.denseblock4.denselayer10.conv1.weight\n\t features.denseblock4.denselayer10.norm2.weight\n\t features.denseblock4.denselayer10.norm2.bias\n\t features.denseblock4.denselayer10.conv2.weight\n\t features.denseblock4.denselayer11.norm1.weight\n\t features.denseblock4.denselayer11.norm1.bias\n\t features.denseblock4.denselayer11.conv1.weight\n\t features.denseblock4.denselayer11.norm2.weight\n\t features.denseblock4.denselayer11.norm2.bias\n\t features.denseblock4.denselayer11.conv2.weight\n\t features.denseblock4.denselayer12.norm1.weight\n\t features.denseblock4.denselayer12.norm1.bias\n\t features.denseblock4.denselayer12.conv1.weight\n\t features.denseblock4.denselayer12.norm2.weight\n\t features.denseblock4.denselayer12.norm2.bias\n\t features.denseblock4.denselayer12.conv2.weight\n\t features.denseblock4.denselayer13.norm1.weight\n\t features.denseblock4.denselayer13.norm1.bias\n\t features.denseblock4.denselayer13.conv1.weight\n\t features.denseblock4.denselayer13.norm2.weight\n\t features.denseblock4.denselayer13.norm2.bias\n\t features.denseblock4.denselayer13.conv2.weight\n\t features.denseblock4.denselayer14.norm1.weight\n\t features.denseblock4.denselayer14.norm1.bias\n\t features.denseblock4.denselayer14.conv1.weight\n\t features.denseblock4.denselayer14.norm2.weight\n\t features.denseblock4.denselayer14.norm2.bias\n\t features.denseblock4.denselayer14.conv2.weight\n\t features.denseblock4.denselayer15.norm1.weight\n\t features.denseblock4.denselayer15.norm1.bias\n\t features.denseblock4.denselayer15.conv1.weight\n\t features.denseblock4.denselayer15.norm2.weight\n\t features.denseblock4.denselayer15.norm2.bias\n\t features.denseblock4.denselayer15.conv2.weight\n\t features.denseblock4.denselayer16.norm1.weight\n\t features.denseblock4.denselayer16.norm1.bias\n\t features.denseblock4.denselayer16.conv1.weight\n\t features.denseblock4.denselayer16.norm2.weight\n\t features.denseblock4.denselayer16.norm2.bias\n\t features.denseblock4.denselayer16.conv2.weight\n\t features.norm5.weight\n\t features.norm5.bias\n\t classifier.weight\n\t classifier.bias\n","output_type":"stream"}]},{"cell_type":"code","source":"# Setup the loss fxn\ncriterion = nn.CrossEntropyLoss()\n\n# Train and evaluate\nmodel_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))","metadata":{"execution":{"iopub.status.busy":"2023-01-05T09:47:55.635077Z","iopub.execute_input":"2023-01-05T09:47:55.635471Z","iopub.status.idle":"2023-01-05T10:05:33.060129Z","shell.execute_reply.started":"2023-01-05T09:47:55.635422Z","shell.execute_reply":"2023-01-05T10:05:33.058306Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch 0/49\n----------\ntrain Loss: 1.6836 Acc: 0.3437\nval Loss: 1.4065 Acc: 0.5250\n\nEpoch 1/49\n----------\ntrain Loss: 1.3658 Acc: 0.5070\nval Loss: 1.2904 Acc: 0.5500\n\nEpoch 2/49\n----------\ntrain Loss: 1.2137 Acc: 0.5660\nval Loss: 1.1946 Acc: 0.6000\n\nEpoch 3/49\n----------\ntrain Loss: 1.1067 Acc: 0.5959\nval Loss: 1.2007 Acc: 0.5750\n\nEpoch 4/49\n----------\ntrain Loss: 0.9840 Acc: 0.6549\nval Loss: 1.2067 Acc: 0.5625\n\nEpoch 5/49\n----------\ntrain Loss: 0.8864 Acc: 0.6954\nval Loss: 1.1991 Acc: 0.6125\n\nEpoch 6/49\n----------\ntrain Loss: 0.7921 Acc: 0.7233\nval Loss: 1.2134 Acc: 0.5875\n\nEpoch 7/49\n----------\ntrain Loss: 0.6893 Acc: 0.7764\nval Loss: 1.1886 Acc: 0.5875\n\nEpoch 8/49\n----------\ntrain Loss: 0.6128 Acc: 0.8016\nval Loss: 1.1481 Acc: 0.6125\n\nEpoch 9/49\n----------\ntrain Loss: 0.5249 Acc: 0.8427\nval Loss: 1.2094 Acc: 0.5625\n\nEpoch 10/49\n----------\ntrain Loss: 0.4389 Acc: 0.8673\nval Loss: 1.1980 Acc: 0.6250\n\nEpoch 11/49\n----------\ntrain Loss: 0.3782 Acc: 0.9011\nval Loss: 1.2403 Acc: 0.6125\n\nEpoch 12/49\n----------\ntrain Loss: 0.3195 Acc: 0.9104\nval Loss: 1.2082 Acc: 0.6125\n\nEpoch 13/49\n----------\ntrain Loss: 0.2487 Acc: 0.9383\nval Loss: 1.2878 Acc: 0.5875\n\nEpoch 14/49\n----------\ntrain Loss: 0.2461 Acc: 0.9343\nval Loss: 1.2770 Acc: 0.6000\n\nEpoch 15/49\n----------\ntrain Loss: 0.2189 Acc: 0.9396\nval Loss: 1.3429 Acc: 0.5750\n\nEpoch 16/49\n----------\ntrain Loss: 0.1458 Acc: 0.9728\nval Loss: 1.3124 Acc: 0.6125\n\nEpoch 17/49\n----------\ntrain Loss: 0.1472 Acc: 0.9648\nval Loss: 1.3313 Acc: 0.6250\n\nEpoch 18/49\n----------\ntrain Loss: 0.1275 Acc: 0.9708\nval Loss: 1.4311 Acc: 0.5875\n\nEpoch 19/49\n----------\ntrain Loss: 0.1135 Acc: 0.9781\nval Loss: 1.4068 Acc: 0.6000\n\nEpoch 20/49\n----------\ntrain Loss: 0.0979 Acc: 0.9841\nval Loss: 1.5490 Acc: 0.5875\n\nEpoch 21/49\n----------\ntrain Loss: 0.0830 Acc: 0.9841\nval Loss: 1.5260 Acc: 0.6125\n\nEpoch 22/49\n----------\ntrain Loss: 0.0666 Acc: 0.9907\nval Loss: 1.5027 Acc: 0.5875\n\nEpoch 23/49\n----------\ntrain Loss: 0.0699 Acc: 0.9881\nval Loss: 1.4770 Acc: 0.6250\n\nEpoch 24/49\n----------\ntrain Loss: 0.0629 Acc: 0.9867\nval Loss: 1.5183 Acc: 0.6250\n\nEpoch 25/49\n----------\ntrain Loss: 0.0584 Acc: 0.9900\nval Loss: 1.4855 Acc: 0.6500\n\nEpoch 26/49\n----------\ntrain Loss: 0.0479 Acc: 0.9927\nval Loss: 1.4812 Acc: 0.6375\n\nEpoch 27/49\n----------\ntrain Loss: 0.0405 Acc: 0.9947\nval Loss: 1.4905 Acc: 0.5750\n\nEpoch 28/49\n----------\ntrain Loss: 0.0401 Acc: 0.9920\nval Loss: 1.5188 Acc: 0.6375\n\nEpoch 29/49\n----------\ntrain Loss: 0.0376 Acc: 0.9947\nval Loss: 1.6229 Acc: 0.6125\n\nEpoch 30/49\n----------\ntrain Loss: 0.0352 Acc: 0.9927\nval Loss: 1.6221 Acc: 0.6375\n\nEpoch 31/49\n----------\ntrain Loss: 0.0349 Acc: 0.9934\nval Loss: 1.6009 Acc: 0.6250\n\nEpoch 32/49\n----------\ntrain Loss: 0.0294 Acc: 0.9973\nval Loss: 1.5107 Acc: 0.6375\n\nEpoch 33/49\n----------\ntrain Loss: 0.0234 Acc: 0.9960\nval Loss: 1.5844 Acc: 0.6375\n\nEpoch 34/49\n----------\ntrain Loss: 0.0265 Acc: 0.9954\nval Loss: 1.6048 Acc: 0.6125\n\nEpoch 35/49\n----------\ntrain Loss: 0.0295 Acc: 0.9940\nval Loss: 1.6890 Acc: 0.6250\n\nEpoch 36/49\n----------\ntrain Loss: 0.0214 Acc: 0.9987\nval Loss: 1.6438 Acc: 0.6500\n\nEpoch 37/49\n----------\ntrain Loss: 0.0188 Acc: 0.9973\nval Loss: 1.6756 Acc: 0.5750\n\nEpoch 38/49\n----------\ntrain Loss: 0.0253 Acc: 0.9940\nval Loss: 1.6779 Acc: 0.6375\n\nEpoch 39/49\n----------\ntrain Loss: 0.0151 Acc: 0.9993\nval Loss: 1.7684 Acc: 0.6000\n\nEpoch 40/49\n----------\ntrain Loss: 0.0125 Acc: 1.0000\nval Loss: 1.7016 Acc: 0.5750\n\nEpoch 41/49\n----------\ntrain Loss: 0.0138 Acc: 0.9993\nval Loss: 1.7457 Acc: 0.5625\n\nEpoch 42/49\n----------\ntrain Loss: 0.0129 Acc: 0.9980\nval Loss: 1.6948 Acc: 0.6125\n\nEpoch 43/49\n----------\ntrain Loss: 0.0146 Acc: 0.9967\nval Loss: 1.6420 Acc: 0.6000\n\nEpoch 44/49\n----------\ntrain Loss: 0.0127 Acc: 0.9987\nval Loss: 1.7787 Acc: 0.5750\n\nEpoch 45/49\n----------\ntrain Loss: 0.0108 Acc: 1.0000\nval Loss: 1.7609 Acc: 0.6000\n\nEpoch 46/49\n----------\ntrain Loss: 0.0219 Acc: 0.9967\nval Loss: 1.6943 Acc: 0.6000\n\nEpoch 47/49\n----------\ntrain Loss: 0.0192 Acc: 0.9967\nval Loss: 1.7599 Acc: 0.6000\n\nEpoch 48/49\n----------\ntrain Loss: 0.0183 Acc: 0.9973\nval Loss: 1.8476 Acc: 0.5875\n\nEpoch 49/49\n----------\ntrain Loss: 0.0146 Acc: 0.9993\nval Loss: 1.8402 Acc: 0.6125\n\nTraining complete in 17m 37s\nBest val Acc: 0.650000\n","output_type":"stream"}]},{"cell_type":"code","source":"class TestDataset(Dataset):\n    \n    def __init__(self, dataframe, root_dir, transform=None):\n        self.dataframe = dataframe\n        self.root_dir = root_dir\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.dataframe)\n    \n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        img_name = os.path.join(self.root_dir,\n                                self.dataframe.iloc[idx, 0])\n        image1 = cv2.imread(img_name)\n        image = Image.fromarray(image1)\n        \n        label =torch.tensor(1)\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image,self.dataframe.iloc[idx, 0]","metadata":{"execution":{"iopub.status.busy":"2023-01-05T10:07:02.925859Z","iopub.execute_input":"2023-01-05T10:07:02.926255Z","iopub.status.idle":"2023-01-05T10:07:02.935649Z","shell.execute_reply.started":"2023-01-05T10:07:02.926218Z","shell.execute_reply":"2023-01-05T10:07:02.934516Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"label_path = \"3rd_year_experiment/emotions/Labels\"\ntest_label_path = os.path.join(label_path, \"ground_truth_test.csv\")\ntest_dataframe = pd.read_csv(test_label_path)\ntest_dataframe.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-05T10:07:05.743479Z","iopub.execute_input":"2023-01-05T10:07:05.743861Z","iopub.status.idle":"2023-01-05T10:07:05.761317Z","shell.execute_reply.started":"2023-01-05T10:07:05.743823Z","shell.execute_reply":"2023-01-05T10:07:05.760414Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"             image\n0    anger/230.jpg\n1  disgust/245.jpg\n2  disgust/249.jpg\n3      joy/253.jpg\n4  disgust/255.jpg","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>anger/230.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>disgust/245.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>disgust/249.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>joy/253.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>disgust/255.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data_path = '3rd_year_experiment/emotions/data/'\ntest_dir = os.path.join(data_path, \"test\")\nprint(os.listdir(test_dir))","metadata":{"execution":{"iopub.status.busy":"2023-01-05T10:07:07.926561Z","iopub.execute_input":"2023-01-05T10:07:07.926953Z","iopub.status.idle":"2023-01-05T10:07:07.933780Z","shell.execute_reply.started":"2023-01-05T10:07:07.926919Z","shell.execute_reply":"2023-01-05T10:07:07.932207Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"['surprise', 'sadness', 'joy', 'anger', '.DS_Store', 'fear', 'disgust']\n","output_type":"stream"}]},{"cell_type":"code","source":"test_dataset = TestDataset(test_dataframe, root_dir=test_dir, transform=transform_valid)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T10:07:10.297983Z","iopub.execute_input":"2023-01-05T10:07:10.298396Z","iopub.status.idle":"2023-01-05T10:07:10.303958Z","shell.execute_reply.started":"2023-01-05T10:07:10.298355Z","shell.execute_reply":"2023-01-05T10:07:10.302775Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"#model_ft.cuda()\nmodel_ft.eval()\nfilenames=[]\nfinalpredictions=[]\nfor inputs, files in test_loader:\n                # print(inputs)\n                # print(files)\n                inputs = inputs.to(device)\n                outputs = model_ft(inputs)\n                _, preds = torch.max(outputs, 1)\n                finalpred=[]\n                for file in files:\n                    filenames.append(file)\n                for pred in preds:\n                    finalpredictions.append(id2label[str(pred.item())])\n                #print(finalpred)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T10:07:12.689169Z","iopub.execute_input":"2023-01-05T10:07:12.689550Z","iopub.status.idle":"2023-01-05T10:07:14.898348Z","shell.execute_reply.started":"2023-01-05T10:07:12.689518Z","shell.execute_reply":"2023-01-05T10:07:14.896382Z"},"trusted":true},"execution_count":25,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/825092620.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0;31m# print(files)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mfinalpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/models/densenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madaptive_avg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/models/densenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, init_features)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minit_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mnew_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/models/densenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mbottleneck_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_checkpoint_bottleneck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mbottleneck_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mnew_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbottleneck_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/models/densenet.py\u001b[0m in \u001b[0;36mbn_function\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbn_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mconcated_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mbottleneck_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcated_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa: T484\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbottleneck_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mbn_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mexponential_average_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         )\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m     return torch.batch_norm(\n\u001b[0;32m-> 2422\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2423\u001b[0m     )\n\u001b[1;32m   2424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 92.00 MiB (GPU 0; 14.76 GiB total capacity; 13.21 GiB already allocated; 79.75 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"],"ename":"RuntimeError","evalue":"CUDA out of memory. Tried to allocate 92.00 MiB (GPU 0; 14.76 GiB total capacity; 13.21 GiB already allocated; 79.75 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error"}]},{"cell_type":"code","source":"df_preds = pd.DataFrame({'image': filenames, \"label\": finalpredictions})\ndf_preds.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-05T09:02:30.765010Z","iopub.execute_input":"2023-01-05T09:02:30.765396Z","iopub.status.idle":"2023-01-05T09:02:30.777862Z","shell.execute_reply.started":"2023-01-05T09:02:30.765361Z","shell.execute_reply":"2023-01-05T09:02:30.776907Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"             image  label\n0    anger/230.jpg      6\n1  disgust/245.jpg      2\n2  disgust/249.jpg      7\n3      joy/253.jpg      4\n4  disgust/255.jpg      2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>anger/230.jpg</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>disgust/245.jpg</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>disgust/249.jpg</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>joy/253.jpg</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>disgust/255.jpg</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_preds.to_csv(\"sample_submission1.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T09:02:45.122425Z","iopub.execute_input":"2023-01-05T09:02:45.123127Z","iopub.status.idle":"2023-01-05T09:02:45.130114Z","shell.execute_reply.started":"2023-01-05T09:02:45.123088Z","shell.execute_reply":"2023-01-05T09:02:45.129152Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"print(len(submission_df))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model_ft,\"EmotionDensenet.pt\")","metadata":{"execution":{"iopub.status.busy":"2023-01-05T10:07:27.077584Z","iopub.execute_input":"2023-01-05T10:07:27.077994Z","iopub.status.idle":"2023-01-05T10:07:27.249574Z","shell.execute_reply.started":"2023-01-05T10:07:27.077958Z","shell.execute_reply":"2023-01-05T10:07:27.248465Z"},"trusted":true},"execution_count":26,"outputs":[]}]}